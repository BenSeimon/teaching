# -*- coding: utf-8 -*-
"""prediciton_solution.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1uSYdy1t90tii3Df6dXwAZlPQGCdeEsPV
"""

import pandas as pd
import numpy as np
from panelsplit.cross_validation import PanelSplit
from panelsplit.application import cross_val_fit_predict
from typing import Union
from sklearn.ensemble import RandomForestClassifier
from functools import reduce
import pickle
import time
from target_engineer import TargetEngineer
from feature_engineer import FeatureEngineer
import time

"""# Load data"""

data_path = "/Users/benseimon/GitHub/teaching/DSDM_forecasting_Apr25/data"
output_path = "/Users/benseimon/GitHub/teaching/DSDM_forecasting_Apr25/output"

#read the data
ucdp = pd.read_csv(f"{data_path}/ucdp.csv", index_col=0)
ucdp = ucdp.set_index(['isocode', 'period']).sort_index() #set index to our id_vars and sort values

#no need for population for demonstration. Keep it if you want a per capita target definition.
ucdp = ucdp.drop(columns=["population"])
ucdp['fatalities_UCDP'] = ucdp['fatalities_UCDP'].astype(int)
#rename column for convenience
ucdp = ucdp.rename(columns={"fatalities_UCDP": "violence"})

"""# Construct panel

## Construct target
"""

#initialize our class
te = TargetEngineer(df=ucdp, unit='isocode', time='period', y_col="violence")

#set threshold and horizon to construct the target
threshold = 0
horizon = 3

#get incidence and onset target dataframes
inc_df = te.incidence(threshold=threshold, horizon=horizon)
inc_target_col = 'inc_anyviolence_th0_h3'
ons_df = te.onset(threshold=threshold, horizon=horizon)
ons_target_col = 'ons_anyviolence_th0_h3'

#save target and onset dfs
inc_df.to_csv(f'{output_path}/incidence.csv')
ons_df.to_csv(f'{output_path}/onset.csv')

"""## Construct features"""

#instantitate feature engineer
fe = FeatureEngineer(groupby_cols='isocode')
y_col = 'violence' #same for all feature engineering
windows = [1, 3, 12, 36, 60] #for rolling mean
thresholds = [0] #for since and ongoing

features = [
    fe.rolling_mean(ucdp, y_col, windows).drop(columns = ['violence']),
    fe.since(ucdp, y_col, thresholds).drop(columns = ['violence']),
    fe.ongoing(ucdp, y_col, thresholds).drop(columns = ['violence']),
    pd.read_csv(f'{data_path}/topics.csv', index_col=0).set_index(['isocode', 'period'])
]

X = reduce(lambda left, right: pd.merge(left, right, left_index=True, right_index=True, how='inner'), features)

#save features
X.to_csv(f'{output_path}/features.csv')

"""# Predictions"""

#set key panelsplit parameters
n_splits = 24
test_size = 1
gap = horizon - 1

"""## Incidence"""

#instantiate panelsplit
inc_ps = PanelSplit(
    periods = inc_df.index.get_level_values('period'),
    n_splits=n_splits,
    test_size=test_size,
    gap = gap
)

inc_final_preds = inc_ps.gen_test_labels(inc_df.merge(X['violence_since_0'], left_index=True, right_index=True, how='left'))

print("Running incidence prediction...")

start_incidence_time = time.time()

inc_preds, fitted_estimators_inc = cross_val_fit_predict(
    estimator=RandomForestClassifier(max_depth=4, max_features=0.2, min_samples_leaf=100, n_jobs=-1, random_state=42),
    X=X,
    y=inc_df[inc_target_col],
    cv=inc_ps,
    method='predict_proba',
    drop_na_in_y=True
)

#save predictions
inc_final_preds['inc_preds'] = inc_preds[:, 1]

end_incidence_time = time.time()

print(f"Incidence prediction time: {(end_incidence_time - start_incidence_time)/60} minutes")



print(f"Saving incidence predictions and fitted estimators")

inc_final_preds.to_csv(f'{output_path}/incidence_predictions.csv')
with open(f'{output_path}/fitted_estimators_inc.pkl', 'wb') as f:
    pickle.dump(fitted_estimators_inc, f)
print("Incidence predictions and fitted estimators saved.")
print("Incidence prediction done.")



"""## Onset"""

ons_ps = PanelSplit(
    periods = ons_df.index.get_level_values('period'),
    n_splits=n_splits,
    test_size=test_size,
    gap = gap
)

ons_final_preds = ons_ps.gen_test_labels(ons_df.merge(X['violence_since_0'], left_index=True, right_index=True, how='left'))

print("Running onset prediction...")

start_onset_time = time.time()

ons_preds, fitted_estimators_ons = cross_val_fit_predict(
    estimator=RandomForestClassifier(max_depth=4, max_features=0.2, min_samples_leaf=100, n_jobs=-1, random_state=42),
    X=X,
    y=ons_df[ons_target_col],
    cv=ons_ps,
    method='predict_proba',
    drop_na_in_y=True
)

#save predictions
ons_final_preds['ons_preds'] = ons_preds[:, 1]

end_onset_time = time.time()

print(f"Onset prediction time: {(end_onset_time - start_onset_time)/60} minutes")

print(f"Saving onset predictions and fitted estimators")

ons_final_preds.to_csv(f'{output_path}/onset_predictions.csv')
with open(f'{output_path}/fitted_estimators_ons.pkl', 'wb') as f:
    pickle.dump(fitted_estimators_ons, f)
print("Onset predictions and fitted estimators saved.")
print("Onset prediction done.")

